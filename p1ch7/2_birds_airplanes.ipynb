{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple image classification using NNs\n",
    "=====================================\n",
    "\n",
    "With a fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1209ab5f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ASCII plots of training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asciichartpy\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepares the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate from the CIFAR data only birds and planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected NN\n",
    "\n",
    "- Input features match number of pixels in image\n",
    "- Output: categorical, number of classes, indicate classification probability\n",
    "\n",
    "![img description](fig7.7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                3072,  # <1>\n",
    "                512,   # <2>\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(\n",
    "                512,   # <2>\n",
    "                n_out, # <3>\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax \n",
    "\n",
    "Softmax is a function that takes a vector of values and produces another vector of the same dimension, where the values satisfy the constraints to represent probabilities. \n",
    "\n",
    "#### PyTorch implementantion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Example tensor\n",
    "logits = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Applying softmax\n",
    "softmax_output = F.softmax(logits, dim=0)\n",
    "\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_output.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By hand\n",
    "\n",
    "Implementing it by hand is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another implementation w/ `nn` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you need to specify the dimension along which softmax is applied\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [1.0, 2.0, 3.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equipping NN to output probabilities\n",
    "\n",
    "Add softmax to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on one image\n",
    "\n",
    "Get one image to test the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.title('A random bird from CIFAR-10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns image into 1D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference from untrained model (random probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4784, 0.5216]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: airplanes\n",
    "1: birds\n",
    "\n",
    "The code below gives the network prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss for classification\n",
    "\n",
    "One good choice is the negative log likelihood (NLL) defined as\n",
    "$$ {\\rm NLL} = - \\sum_{i=0}^{N} \\log p({\\rm correct}).$$\n",
    "\n",
    "Our loss for classification can be computed as follows. For each sample in the batch:\n",
    "\n",
    "1. Run the forward pass, and obtain the output values from the last (linear) layer.\n",
    "2. Compute their softmax, and obtain probabilities.\n",
    "3. Take the predicted probability corresponding to the correct class (the likelihood of the parameters). Note that we know what the correct class is because\n",
    "it’s a supervised problem—it’s our ground truth.\n",
    "4. Compute its logarithm, slap a minus sign in front of it, and add it to the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Comparison between loss definitions \n",
    "\n",
    "Not in the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor([\n",
    "    [0.6, 0.4],\n",
    "    [0.9, 0.1],\n",
    "    [0.3, 0.7],\n",
    "    [0.2, 0.8],\n",
    "])\n",
    "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
    "\n",
    "truth = torch.zeros((4,2))\n",
    "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(out):\n",
    "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
    "mse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000],\n",
       "        [0.9000],\n",
       "        [0.7000],\n",
       "        [0.8000]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.gather(dim=1, index=class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3024])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likelihood(out):\n",
    "    prod = 1.0\n",
    "    for x in out.gather(dim=1, index=class_index):\n",
    "        prod *= x\n",
    "    return prod\n",
    "\n",
    "likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1960])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neg_log_likelihood(out):\n",
    "    return -likelihood(out).log()\n",
    "\n",
    "neg_log_likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0750, 0.1500, 0.2500, 0.4750])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0 = out.clone().detach()\n",
    "out0[0] = torch.tensor([0.9, 0.1]) # more right\n",
    "\n",
    "out2 = out.clone().detach()\n",
    "out2[0] = torch.tensor([0.4, 0.6]) # slightly wrong\n",
    "\n",
    "out3 = out.clone().detach()\n",
    "out3[0] = torch.tensor([0.1, 0.9]) # very wrong\n",
    "\n",
    "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
    "mse_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-50.0000,   0.0000,  66.6667, 216.6667])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((mse_comparison / mse_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7905, 1.1960, 1.6015, 2.9878])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_comparison = torch.tensor([neg_log_likelihood(o) \n",
    "                               for o in [out0, out, out2, out3]])\n",
    "nll_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-33.9016,   0.0000,  33.9017, 149.8121])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((nll_comparison / nll_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-104.,    0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(log_softmax(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the loss with the previous image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7303, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Use MPS if available, otherwise fall back to CPU\n",
    "#device = torch.device(\"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "#model.to(device)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach A: updating the model over the whole dataset\n",
    "\n",
    "This is the most detailed approach. We evaluate the model with the entire dataset. However, it is slow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Epoch 99 , Loss 15.9819\n",
      "    1.35  ┤     ╭╮╭╮       ╭╮╭╮                               ╭╮╭╮  ╭───╮      ╭╮      ╭╮            ╭╮      ╭\n",
      "    0.93  ┤ ╭╮╭─╯╰╯╰──╮╭─╮╭╯╰╯╰╮╭───────────────╮╭╮╭╮     ╭╮╭─╯╰╯╰╮╭╯   ╰─╮╭───╯│╭──╮╭─╯╰╮╭╮ ╭╮ ╭╮   │╰╮     │\n",
      "    0.50  ┼─╯││       ╰╯ ╰╯    ╰╯               ╰╯╰╯╰─╮╭╮╭╯││     ╰╯      ╰╯    ╰╯  ╰╯   │││╭╯│╭╯╰─╮╭╯ │     │\n",
      "    0.07  ┤  ╰╯                                       ││╰╯ ││                            ╰╯││ ╰╯   ││  │     │\n",
      "   -0.36  ┤                                           ╰╯   ││                              ╰╯      ││  │╭╮ ╭╮│\n",
      "   -0.78  ┤                                                ││                                      ││  │││╭╯╰╯\n",
      "   -1.21  ┤                                                ╰╯                                      ││  ││││\n",
      "   -1.64  ┤                                                                                        ╰╯  ││││\n",
      "   -2.07  ┼                                                                                            ││││\n",
      "   -2.50  ┤                                                                                            ╰╯││\n",
      "   -2.92  ┤                                                                                              ╰╯\n",
      "   -3.35  ┤\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 100\n",
    "\n",
    "lossList=[]\n",
    "epochList=[]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        # move data to GPU\n",
    "        #img = img.to(device)\n",
    "        #img = img.float().to(device)\n",
    "        #label = torch.tensor([label]).to(device)\n",
    "\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    lossList.append(np.log10(float(loss)))\n",
    "    epochList.append(epoch)\n",
    "    clear_output(wait=True)\n",
    "    print(\"              Epoch\", epoch, \", Loss\",round(float(loss),4))\n",
    "    print(asciichartpy.plot(lossList, {'height': 10}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach C: average updates using minibatches\n",
    "\n",
    "Here we pick a random subset of the data at each iteration of the training loop. This speeds up convergence, though at the cost of less accurate optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Epoch 99 , Loss 0.0188\n",
      "   -0.23  ┼─╮╭╮╭╮  ╭╮  ╭╮     ╭╮\n",
      "   -0.43  ┤ ╰╯╰╯│╭─╯╰─╮││ ╭╮╭─╯╰╮   ╭╮  ╭╮     ╭╮\n",
      "   -0.63  ┤     ╰╯    ╰╯╰─╯╰╯   ╰───╯╰──╯╰╮  ╭╮│╰╮    ╭╮                ╭╮\n",
      "   -0.84  ┤                               │╭─╯╰╯ ╰─╮╭╮││╭╮ ╭╮ ╭─╮      ╭╯╰╮\n",
      "   -1.04  ┤                               ╰╯       ╰╯││╰╯│ ││╭╯ ╰╮    ╭╯  │        ╭╮\n",
      "   -1.24  ┤                                          ╰╯  ╰─╯╰╯   ╰╮ ╭╮│   │╭──╮   ╭╯│╭╮    ╭──╮\n",
      "   -1.45  ┤                                                       │╭╯╰╯   ╰╯  ╰─╮ │ ││╰──╮ │  │  ╭╮\n",
      "   -1.65  ┤                                                       ╰╯            ╰─╯ ╰╯   │ │  ╰╮ ││  ╭──╮   ╭─\n",
      "   -1.85  ┤                                                                              ╰─╯   │╭╯╰╮╭╯  ╰╮╭─╯\n",
      "   -2.06  ┤                                                                                    ││  ╰╯    ╰╯\n",
      "   -2.26  ┤                                                                                    ╰╯\n",
      "   -2.47  ┤\n"
     ]
    }
   ],
   "source": [
    "lossList=[]\n",
    "epochList=[]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    lossList.append(np.log10(float(loss)))\n",
    "    epochList.append(epoch)\n",
    "    clear_output(wait=True)\n",
    "    print(\"              Epoch\", epoch, \", Loss\",round(float(loss),4))\n",
    "    print(asciichartpy.plot(lossList, {'height': 10}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks accuracy of trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.814000\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complicated architecture"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specification below is the same as with `nn.LogSoftmax` and `nn.NLLLoss`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Epoch 99 , Loss 0.0\n",
      "   -0.09  ┤                 ╭╮              ╭╮╭╮\n",
      "   -0.44  ┼──────────────╮╭─╯╰╮╭──╮╭╮ ╭╮   ╭╯││╰─╮                                    ╭╮\n",
      "   -0.79  ┤              ╰╯   ╰╯  ╰╯╰─╯╰╮╭─╯ ╰╯  ╰─╮   ╭╮ ╭╮  ╭╮         ╭╮           ││\n",
      "   -1.13  ┤                             ╰╯         ╰───╯╰─╯╰╮ ││     ╭╮  ││          ╭╯│          ╭╮\n",
      "   -1.48  ┤                                                 ╰─╯╰╮    ││  ││╭─╮    ╭╮ │ │          ││╭╮\n",
      "   -1.83  ┤                                                     ╰──╮ ││ ╭╯╰╯ │╭╮╭─╯╰╮│ ╰╮       ╭─╯│││    ╭╮\n",
      "   -2.18  ┤                                                        │╭╯╰─╯    ╰╯││   ╰╯  │ ╭───╮ │  ││╰╮ ╭╮││╭╮\n",
      "   -2.52  ┤                                                        ╰╯          ╰╯       ╰─╯   ╰╮│  ╰╯ ╰─╯╰╯│││\n",
      "   -2.87  ┤                                                                                    ╰╯          ││╰\n",
      "   -3.22  ┤                                                                                                ││\n",
      "   -3.56  ┤                                                                                                ╰╯\n",
      "   -3.91  ┼\n"
     ]
    }
   ],
   "source": [
    "lossList=[]\n",
    "epochList=[]\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    lossList.append(np.log10(float(loss)))\n",
    "    epochList.append(epoch)\n",
    "\n",
    "    #print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
    "    clear_output(wait=True)\n",
    "    print(\"              Epoch\", epoch, \", Loss\",round(float(loss),4))\n",
    "    print(asciichartpy.plot(lossList, {'height': 10}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.999600\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808000\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of parameters in NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of *trainable* parameters in NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() \n",
    "     for p in model.parameters() \n",
    "     if p.requires_grad == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manual calculation\n",
    "\n",
    "Here is the manual calculation of the number of parameters for the network below.\n",
    "\n",
    "```python\n",
    "      nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "```\n",
    "\n",
    "For each layer, the number of parameters is $$N(N_{\\rm in},N_{\\rm out}) = N_{\\rm in} \\times N_{\\rm out} + N_{\\rm out} = N_{\\rm out} (1+N_{\\rm in} ).$$ \n",
    "Thus, for the network above we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparam = lambda nin,nout: nout*(1+nin)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nparam(3072,1024) + nparam(1024,512) + nparam(512,128) + nparam(128,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1574402"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_model = nn.Sequential(\n",
    "                nn.Linear(3072, 512),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(512, 2),\n",
    "                nn.LogSoftmax(dim=1))\n",
    "\n",
    "sum([p.numel() for p in first_model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1573376"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in nn.Linear(3072, 512).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3146752"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in nn.Linear(3072, 1024).parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 3, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1, 2, 0), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAF4lJREFUeJztnVuMndV5hp/P40NssMHHsfEB24QQCEkxmqAqVBVVDqJVJBJFieKLiEpRnIsgNVIuGnETbiqhKofmAkVyCgqRckIKabhAbSJUCRIpFoYQsLExjuMTHp9iO8YGYmN/vZjtdurMetfMnvHeg9b7SMgz+5v/X2uv/b/8e+93fd8XmYkxpj1m9HsCxpj+YPEb0ygWvzGNYvEb0ygWvzGNYvEb0ygWvzGNYvEb0ygWvzGNMnMyB0fE3cC3gQHg3zPzQfX3c+fOzQULFnQ11ltvvVWMzZ49uxibNWtWMXbx4kU55rlz54qxP//5z8XYhQsXirGBgQE5Zm1OJdROzdo5VVzFartDZ8zo7t4SEcWYej0B5s2bV4yp60RdXzVmzuxORmp9atdJaY1OnTrF2bNnyws4iq7FHxEDwEPAR4GDwLMR8URmvlw6ZsGCBWzcuHHMWO1CevXVV4uxlStXFmPLly8vxt5880055v79+4uxPXv2FGNnzpwpxubPny/HfOONN4oxJQr1P6Pa8zx79mxXsfPnz8vzvutd7yrG1HNRIh0cHJRjbtiwoRhbs2ZNMbZ79255XsWiRYuKMXVdq2uhdp3MmTNnzMcfeughedxoJvO2/w5gd2buycxzwI+BeyZxPmNMD5mM+FcCB0b9frDzmDHmHcBkxD/W+7a/eI8TEZsiYmtEbK29/TTG9I7JiP8gsHrU76uAQ5f/UWZuzsyhzByaO3fuJIYzxkwlkxH/s8CNEbEuImYDnwWemJppGWOuNF1/25+Zb0fEfcB/MWL1PZKZ29UxZ8+eZcuWLWPG7rzzTjnejTfeWIypb44XLlxYjK1du1aOqb7p3rdvXzGmvu2v2ULq3ZE6Vh33+uuvyzFPnTpVjCnL6brrrpPnVbabcifUt/1XX321HFM5DMr52bVrVzF29OhROaY6r1q/q666qqsYlF/vmkU4mkn5/Jn5JPDkZM5hjOkP3uFnTKNY/MY0isVvTKNY/MY0isVvTKNY/MY0yqSsvokyMDBQ9N2V1ww6c0pl3/3xj38sxj70oQ/JMa+99tpiTPmw69atK8ZqKanKp1VrpLz8WvZdKUMMdHbZsmXL5HnVvgSVRafSvms+v3pd1PPsdn9A7Vg1XxVTc4Xy2qo9L5fjO78xjWLxG9MoFr8xjWLxG9MoFr8xjWLxG9MoPbX65syZww033DBmrJY2qSriqnTWgwcPFmMqLRe0laXsH1Xx9k9/+pMc8/jx48WYsn9UlSSV1gw69VbZdbWqwGq+qhDnBz/4wWLs9ttvl2OqNGxlsypbt5Ymq6rwqtRltbYTSc0dTa0Q7mh85zemUSx+YxrF4jemUSx+YxrF4jemUSx+Yxqlp1bfjBkzirbS4sWL5bHdNmBUFtivf/1rOeaSJUuKsQMHDhRjKgNx/fr1ckzVq081Dl29enUxVsuYHB4eLsaUdTaZpqPXX399MfaRj3ykGPvUpz4lx3z++eeLsdOnTxdjK1asKMZOnjwpx7wS1Cy7bhu6jsZ3fmMaxeI3plEsfmMaxeI3plEsfmMaxeI3plF6avXNnDmzaOmp7CfQVqAqXrlq1apiTFk/oItBKstOWUO1Ap633HJLMfbqq68WY8oifOutt+SYEyn6OJq3335bxtXrosa85pprirFaAU9l+6pCryqrVBWBBW0Jq8xQdVzN6lNZruNlUuKPiL3A68AF4O3MHJr0jIwxPWEq7vx/l5nlJHRjzLTEn/mNaZTJij+BX0TEcxGxaaw/iIhNEbE1IraqraLGmN4y2bf9d2bmoYhYBvwyInZm5tOj/yAzNwObAVatWjX+GkPGmCvKpO78mXmo8+9R4GfAHVMxKWPMladr8UfEVREx/9LPwMeAbVM1MWPMlWUyb/sHgZ91/NqZwA8z8z/VARFRrFha8/mV16r2ACivXlVdBe2dqyq8yld/5ZVX5JjK+1Xe7pEjR7o6DnSjyclUmFXjTqTK7Gh27twp4yqlVzUHVd9HqWsI9PWnmo6q/Qy1vQWlPRYTWdeuxZ+Ze4C/6vZ4Y0x/sdVnTKNY/MY0isVvTKNY/MY0isVvTKP0NKUXylZErXqvSg9V9oZKHa1VQFXHqtTSlStXFmOqUi7otF1lySmLUNmAoKv7KjuvZvWp10VVY1bnffHFF+WYjz/+eDGmGrqeOXOmGFu3bp0cUzVCVdeQGrNm2ZWqUrtRpzGmisVvTKNY/MY0isVvTKNY/MY0isVvTKNMm0adtcyp1157rRhTlonKqpo/f74cU1lgqgrv0qVLizFVXRZg3759xZjKklOWksrMA22tKXtMZaXVWLNmTTGmmmY+88wz8rzbtpWzyt/97ncXY2r9VGVf0E1blT07Z86cYqxmQ5esvolU9fWd35hGsfiNaRSL35hGsfiNaRSL35hGsfiNaZSeWn0RUbS6ak0fFefOnSvGzp8/X4zVMglVEcWS1QLaplFFQUE3D1XPpdsinKAtT5W9qJqVgrZvVRaiei41K0tZsMeOHevqvHv27JFjqqxJlfGn1kDZ11C2Z2tNWUfjO78xjWLxG9MoFr8xjWLxG9MoFr8xjWLxG9MoFr8xjVL1+SPiEeDjwNHMvLXz2CLgJ8BaYC/wmcw8WTtXZha96lqjTuWJnjhxohg7ebI8rWXLlskxVWrprl27irFum3iC9sbVsSr1tlZld/ny5cWY2gtx7bXXyvMuWrSoGBscHCzGDh06VIypfRC1MWtpsiVq16ZK+VXPZfXq1cWYSjGG8r4YteflcsZz5/8ecPdlj30VeCozbwSe6vxujHkHURV/Zj4NXH5rvQd4tPPzo8AnpnhexpgrTLef+Qczcxig82/x/XNEbIqIrRGxtbZl0RjTO674F36ZuTkzhzJzSO0TN8b0lm7FfyQiVgB0/tVFzowx045uxf8EcG/n53uBn0/NdIwxvWI8Vt+PgLuAJRFxEPga8CDwWER8HtgPfHo8gymrT6XPgk7zVFaWSmetfQxRzSTVfFWKp7IBxzOnEsrGqlVGVlVkVaxmW86YUb633HzzzcWYasq6Y8cOOaZ6zdS1oFKBa+t39uzZYuzw4cPF2MGDB4sxVQFaMZFGnVXxZ+bGQujD4x7FGDPt8A4/YxrF4jemUSx+YxrF4jemUSx+Yxql5406S5bdZHb/KStGWWA1q0pZQ2pMZTfVstIU6ryq+rGq+gu60aSyJieT1acy5ZRFuHPnTjmmWofafEvUqh+ra1ddJyoDr5aBWMo4rVUaHo3v/MY0isVvTKNY/MY0isVvTKNY/MY0isVvTKP03OorNYWsFZk8depUV2Mq66fWHFTZUSqmil6qQpugbS5l/6j1qxV17NZyqr1mqimpymhTBUVrlrAqrKpQmXkq4w9gwYIFxZjKilTrV2voWmoUO5Eipb7zG9MoFr8xjWLxG9MoFr8xjWLxG9MoFr8xjWLxG9MoPfX5z507V0wfVT4raF+428qr11xzjRxTVUJV3vhkmluq/QNqPt16zaCfi4rVKhErH1vtsVB7HWqv2YULF4oxtUdArVFtP0i366dez+HhYTlmqXp0yf8fC9/5jWkUi9+YRrH4jWkUi9+YRrH4jWkUi9+YRhlPo85HgI8DRzPz1s5jDwBfAI51/uz+zHyydq4333yT3/3ud2PGlEUDcOzYMRkvsWzZsmKsZrutXr26GFOVaVVVYGVjgbaGlHVWSpWuHQc6DVSdVzXUrMXVnJTdOXv2bDnmkiVLirGVK1cWY8oGrKXXHj1a7lAfEV2NWau4fPLkyTEfn+qU3u8Bd4/x+Lcy87bOf1XhG2OmF1XxZ+bTwIkezMUY00Mm85n/voh4MSIeiYiFUzYjY0xP6Fb83wFuAG4DhoFvlP4wIjZFxNaI2FrrkGOM6R1diT8zj2Tmhcy8CHwXuEP87ebMHMrMoVKrLmNM7+lK/BExulHYJ4FtUzMdY0yvGI/V9yPgLmBJRBwEvgbcFRG3AQnsBb44nsHOnTvHvn37xozVqtqqbCVlDanzKlsIYP369cWYqiasmnHWmj6q56nGVNZQzepTazQ4OFiMKesM4Pjx48VYLdOwhLJYgWIjWNCW3U033dTVfEBn56nXUz2XWsXgUpbroUOH5HGjqYo/MzeO8fDD4x7BGDMt8Q4/YxrF4jemUSx+YxrF4jemUSx+YxrF4jemUXpavffixYvFdNdahVQVV16q2lKsusGC9mHPnDlTjKlU4ZpPXarKCvVuuyVUajJob3zevHnFWK1jrjpWVWtW+yRq69dtCrJKy61dJ6qisFoDlX5b24NS2i+i9lZcju/8xjSKxW9Mo1j8xjSKxW9Mo1j8xjSKxW9Mo/TU6lPUrD6FquiqqgKrJp6gbRqVmqsqtr73ve+VYx45cqQYU804VdNM9Tygbp+VqBVnUVbWiRPlspCHDx8uxpQNCNrqU9fYnj17irFaRVz1eivLTtnFKk0dys+zlr49Gt/5jWkUi9+YRrH4jWkUi9+YRrH4jWkUi9+YRump1TdjxoyiPVRrYKnsFHVst5lloG1CZamoyrQqAwx0FV4VU+tTa4Kq1k/ZoTVbqdvMve3btxdjtaw1ZYeq9VNz3b9/vxxToWxotX41e7FklU7EMved35hGsfiNaRSL35hGsfiNaRSL35hGsfiNaZTxNOpcDXwfWA5cBDZn5rcjYhHwE2AtI806P5OZJ9W5MrNot9RsI5Wtpaw1Ze/89re/lWOqOalimsoe27VrlxxTzVdlgSlrqGYvquw8VdhSFcSszUlZa6qIac3KUsVTlWWnriG17gC7d+8uxlRWn4otW7ZMjqmyOMfLeO78bwNfycybgb8GvhQRtwBfBZ7KzBuBpzq/G2PeIVTFn5nDmfl85+fXgR3ASuAe4NHOnz0KfOJKTdIYM/VM6DN/RKwFNgBbgMHMHIaR/0EA+n2KMWZaMe7tvRFxNfBT4MuZeVptJ73suE3AJtBbHY0xvWVcd/6ImMWI8H+QmY93Hj4SESs68RXAmN8MZebmzBzKzKFZs2ZNxZyNMVNAVfwxcot/GNiRmd8cFXoCuLfz873Az6d+esaYK8V43vbfCXwOeCkiXug8dj/wIPBYRHwe2A98+spM0RhzJaiKPzN/BZQ+4H94ogOWviuopTCqtFTVjPONN94oxk6elNsSePnll4sx5cer+fzmN7+RY950003F2PXXX1+MKf+7trZqP4Oqanvo0CF5XtUgVFWnVT7/H/7wBzmm+l5JNXRV1ZjVHhPQDUvV81Re/YoVK+SYCxcuHPNxV+81xlSx+I1pFIvfmEax+I1pFIvfmEax+I1plJ5X7y3ZIsqGATh16lQxpuwdZTd94AMfkGOqCrN79+4txpQlp2xA0Bbi3LlzizGVYlxbW4WyWGtNM1UqrEoHXrVqVTG2dOlSOaZKX1bPRV1DmSnHXL9+fTGm0n3V66KalSpqtu5ofOc3plEsfmMaxeI3plEsfmMaxeI3plEsfmMapadW32RYvHhxMaasIWWP1aoR3XrrrcWYahipmkXWCpps27atGFu+fHkxpiyeWgUltQ7KrqtVkFUZbao56NDQUDGmKg0DbNmypasxVdXfmj2rrF113tdee60YqzUHLZ231pR1NL7zG9MoFr8xjWLxG9MoFr8xjWLxG9MoFr8xjdJTq29gYKBYDFE1twS47rrrijFlAyqb5sCBA3LM973vfcXY2rVrizFlca1Zs0aOuX379mJMFa9U86k11FQZiqqZqXqeoF9TVaRTFV1V1hno7EZl+6oiner6Am0hbtiwoRjbuXNnMfbYY4/JMRctWiTj48F3fmMaxeI3plEsfmMaxeI3plEsfmMaxeI3plEsfmMaperzR8Rq4PvAcuAisDkzvx0RDwBfAI51/vT+zHxSDjZzJkuWLBkzVqswq/z6s2fPFmPr1q0rxmpNH1VTTZUmqzzsWhqxarj57LPPFmPvec97ijHVhBK0r668epW6DNr/Vr66qtRcq6Sr9gGotVep1rfccoscUzV8Vdf14OBgMabSt6Gcaj2R6r3j2eTzNvCVzHw+IuYDz0XELzuxb2Xm18c9mjFm2jCeFt3DwHDn59cjYgew8kpPzBhzZZnQZ/6IWAtsAC6VS7kvIl6MiEciYsyG4RGxKSK2RsTWWkUUY0zvGLf4I+Jq4KfAlzPzNPAd4AbgNkbeGXxjrOMyc3NmDmXmUK0EkzGmd4xL/BExixHh/yAzHwfIzCOZeSEzLwLfBe64ctM0xkw1VfHHyFekDwM7MvObox5fMerPPgmUK08aY6Yd4/m2/07gc8BLEfFC57H7gY0RcRuQwF7gi7UTZWYxDbRWCbbU4BN0Gqc6r7K4AJ5++uliTDUAVRZYrSqrsvpOnDhRjKlKsGquoFNzVUytO+hKuso+W7hwzK+PAG2rARw9erQYUzbYkSNHirH3v//9ckxVPVqlSytuv/12GS/ZvjUreTTj+bb/V8BYZ5SevjFmeuMdfsY0isVvTKNY/MY0isVvTKNY/MY0Sk+r92Ym58+f7+pY1TBSWU67d+8uxmoNLAcGBoox9TxqFXoVqtKuep7PPfdcMaay5EA/T7V+qhouaNvt2LFjxZhqfFmzstTrojIC1drWLGFVOVlZzWoNatWsV6xYMebjyvK9HN/5jWkUi9+YRrH4jWkUi9+YRrH4jWkUi9+YRump1XfhwoVisU2VzQY6m2vOnDnF2Lx584ox1fwTdBFFZf8ou6lk0VxCFdtUWWmqStLvf/97OaZaB2VjKYsQum/UqZ5LrVGnWj81XzXmtm06W11ZxocPHy7GVNHQmg1dKv5ZK9Y6Gt/5jWkUi9+YRrH4jWkUi9+YRrH4jWkUi9+YRrH4jWmUnvr8ilpjwlKDT9DNEJcuXdpVDPT+AeULK29XNRWFkb0QJVRjR1Xt9fjx43LM4eHhYkytQa2SrkLtv9i3b18xpvYHACxevLgYU6nWp0+fLsZU1WTQFXpVqrBKMa6l9JYqRNf2XozGd35jGsXiN6ZRLH5jGsXiN6ZRLH5jGsXiN6ZRQtkNUz5YxDFgtI+zBNA+VG/xfDTTbT4w/ebU7/lcn5naw+7QU/H/xeARWzNzqG8TuAzPRzPd5gPTb07TbT4Kv+03plEsfmMapd/i39zn8S/H89FMt/nA9JvTdJtPkb5+5jfG9I9+3/mNMX2iL+KPiLsj4pWI2B0RX+3HHC6bz96IeCkiXoiIrX2awyMRcTQito16bFFE/DIiXu38u7DP83kgIl7rrNMLEfEPPZzP6oj474jYERHbI+KfOo/3ZY3EfPq2RhOl52/7I2IA2AV8FDgIPAtszMyXezqR/z+nvcBQZvbNn42IvwXOAN/PzFs7j/0rcCIzH+z8T3JhZv5zH+fzAHAmM7/eizlcNp8VwIrMfD4i5gPPAZ8A/pE+rJGYz2fo0xpNlH7c+e8Admfmnsw8B/wYuKcP85hWZObTwOWJ4/cAj3Z+fpSRi6uf8+kbmTmcmc93fn4d2AGspE9rJObzjqEf4l8JHBj1+0H6v2gJ/CIinouITX2ey2gGM3MYRi42YFmf5wNwX0S82PlY0LOPIaOJiLXABmAL02CNLpsPTIM1Gg/9EH+M8Vi/LYc7M/N24O+BL3Xe8pq/5DvADcBtwDDwjV5PICKuBn4KfDkzy+V3+jefvq/ReOmH+A8Cq0f9vgo41Id5/C+Zeajz71HgZ4x8NJkOHOl8trz0GfNoPyeTmUcy80JmXgS+S4/XKSJmMSK0H2Tm452H+7ZGY82n32s0Efoh/meBGyNiXUTMBj4LPNGHeQAQEVd1vrAhIq4CPgbo5my94wng3s7P9wI/7+NcLonrEp+kh+sUEQE8DOzIzG+OCvVljUrz6ecaTZS+bPLp2B//BgwAj2Tmv/R8Ev83l/WM3O1hpKDpD/sxn4j4EXAXI1lhR4CvAf8BPAasAfYDn87MnnwJV5jPXYy8nU1gL/DFS5+3ezCfvwGeAV4CLnUsvZ+Rz9k9XyMxn430aY0minf4GdMo3uFnTKNY/MY0isVvTKNY/MY0isVvTKNY/MY0isVvTKNY/MY0yv8AZfmG8htYlK4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 30, 30])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor([[-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0],\n",
    "                                   [-1.0, 0.0, 1.0]])\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = nn.MaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ellipsis is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-94807a3b1438>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             ...)\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\book\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_item_by_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\book\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36madd_module\u001b[1;34m(self, name, module)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             raise TypeError(\"{} is not a Module subclass\".format(\n\u001b[1;32m--> 173\u001b[1;33m                 torch.typename(module)))\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_six\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             raise TypeError(\"module name should be a string. Got {}\".format(\n",
      "\u001b[1;31mTypeError\u001b[0m: ellipsis is not a Module subclass"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # WARNING: something missing here\n",
    "            nn.Linear(512, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act4 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act4(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = Net()\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Linear(8*8*8, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, 2))\n",
    "\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Check if MPS is available and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        return self.fc(x)\n",
    "\n",
    "# Load the dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize the network and move it to the device\n",
    "model = SimpleNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 11):  # Train for 10 epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}, Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1.00  ┤     ╭────╮                          ╭───╮                          ╭───╮\n",
      "    0.82  ┤   ╭─╯    ╰╮                       ╭─╯   ╰─╮                      ╭─╯   ╰─╮                       ╭\n",
      "    0.64  ┤  ╭╯       ╰─╮                    ╭╯       ╰╮                    ╭╯       ╰╮                    ╭─╯\n",
      "    0.45  ┤ ╭╯          ╰╮                 ╭─╯         ╰╮                  ╭╯         ╰─╮                 ╭╯\n",
      "    0.27  ┤╭╯            ╰╮               ╭╯            ╰╮                ╭╯            ╰╮               ╭╯\n",
      "    0.09  ┼╯              ╰╮             ╭╯              ╰╮              ╭╯              ╰╮             ╭╯\n",
      "   -0.09  ┼                ╰╮           ╭╯                ╰╮            ╭╯                ╰╮           ╭╯\n",
      "   -0.27  ┤                 ╰╮         ╭╯                  ╰╮          ╭╯                  ╰╮         ╭╯\n",
      "   -0.45  ┤                  ╰╮       ╭╯                    ╰╮       ╭─╯                    ╰╮       ╭╯\n",
      "   -0.64  ┤                   ╰─╮   ╭─╯                      ╰─╮    ╭╯                       ╰─╮   ╭─╯\n",
      "   -0.82  ┤                     ╰───╯                          ╰────╯                          ╰───╯\n",
      "   -1.00  ┤\n"
     ]
    }
   ],
   "source": [
    "from asciichartpy import plot\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "import time\n",
    "\n",
    "data = []\n",
    "for i in range(100):\n",
    "    data.append(math.sin(i * 0.2))\n",
    "    clear_output(wait=True)\n",
    "    print(plot(data, {'height': 10}))\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.94117468, -3.70962428, -3.49444891, ..., -4.11315011,\n",
       "       -3.92370215, -4.2265296 ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(lossList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.4552634734248416,\n",
       " -0.48678398136115225,\n",
       " -0.414733637590118,\n",
       " -0.4224837288878089,\n",
       " -0.4571809803473611,\n",
       " -0.42879356789716566,\n",
       " -0.2931855981771007,\n",
       " -0.3778548369441285,\n",
       " -0.5251711890726496,\n",
       " -0.41214582237003317,\n",
       " -0.4505572984611475,\n",
       " -0.3284453445365033,\n",
       " -0.4654746553830507,\n",
       " -0.38933492799389036,\n",
       " -0.4835746420857927,\n",
       " -0.5207681185787738,\n",
       " -0.39618885706319396,\n",
       " -0.3736952421619068,\n",
       " -0.26796743439828136,\n",
       " -0.41555186256408627,\n",
       " -0.5842482480929493,\n",
       " -0.30772205131856206,\n",
       " -0.4091568567636957,\n",
       " -0.3728881372807883,\n",
       " -0.45869987623499114,\n",
       " -0.4469985926931943,\n",
       " -0.49774045381683196,\n",
       " -0.49086710833082825,\n",
       " -0.2668893421885412,\n",
       " -0.3691460480468087,\n",
       " -0.4173543907963021,\n",
       " -0.45605271938671527,\n",
       " -0.4710916099635415,\n",
       " -0.20604531427461695,\n",
       " -0.39008432369604934,\n",
       " -0.4522747409463707,\n",
       " -0.3704047431569905,\n",
       " -0.4511830592142935,\n",
       " -0.33862594177730054,\n",
       " -0.45163587220591295,\n",
       " -0.5438771708132604,\n",
       " -0.3242946740349136,\n",
       " -0.3911084138076739,\n",
       " -0.39803828292593485,\n",
       " -0.466636752746449,\n",
       " -0.6654638836737988,\n",
       " -0.49780564649181624,\n",
       " -0.47681297167899533,\n",
       " -0.3732075592288051,\n",
       " -0.40716897004734715,\n",
       " -0.34974720869731357,\n",
       " -0.4820569289499359,\n",
       " -0.4709881913042092,\n",
       " -0.37944383167618845,\n",
       " -0.535714527276605,\n",
       " -0.5728429106232454,\n",
       " -0.31774382708092364,\n",
       " -0.5021418266054829,\n",
       " -0.3430451121019972,\n",
       " -0.6793130331115129,\n",
       " -0.4506915125092121,\n",
       " -0.4405757712909144,\n",
       " -0.27259737349999547,\n",
       " -0.3256617184329574,\n",
       " -0.301300743726158,\n",
       " -0.5781400367690869,\n",
       " -0.40559532277760035,\n",
       " -0.2908086945941612,\n",
       " -0.40945961733839925,\n",
       " -0.3889975935748546,\n",
       " -0.34376423831052805,\n",
       " -0.33858865588541015,\n",
       " -0.3395209728943923,\n",
       " -0.45944014540625155,\n",
       " -0.5118997503418143,\n",
       " -0.4409599147273916,\n",
       " -0.3996234217449122,\n",
       " -0.3534041984309411,\n",
       " -0.2773097520751754,\n",
       " -0.5257750814099919,\n",
       " -0.3499867646187605,\n",
       " -0.250818809083403,\n",
       " -0.3920339165951783,\n",
       " -0.34517704368660285,\n",
       " -0.48800798730093553,\n",
       " -0.4395219712060618,\n",
       " -0.4173484355668308,\n",
       " -0.4880010596149907,\n",
       " -0.4050532895289863,\n",
       " -0.3306673981222491,\n",
       " -0.4255688574086087,\n",
       " -0.44686254519167823,\n",
       " -0.5206680506808462,\n",
       " -0.47809861706183493,\n",
       " -0.4026970089980827,\n",
       " -0.332268594469458,\n",
       " -0.3502800311378664,\n",
       " -0.37507307457738576,\n",
       " -0.494945536844985,\n",
       " -0.31934432461958534,\n",
       " -0.34421965156450857,\n",
       " -0.42474360507553893,\n",
       " -0.4930528197695117,\n",
       " -0.4981284557097559,\n",
       " -0.381160491731829,\n",
       " -0.46283293421342653,\n",
       " -0.42159101514076924,\n",
       " -0.5413563975746318,\n",
       " -0.4940377697905218,\n",
       " -0.5749271272472998,\n",
       " -0.39931679184082636,\n",
       " -0.5137212068061348,\n",
       " -0.3250719148799593,\n",
       " -0.4001925415682134,\n",
       " -0.5104025867028673,\n",
       " -0.38872184504183727,\n",
       " -0.5042425572781146,\n",
       " -0.3648246160992917,\n",
       " -0.32270576640810544,\n",
       " -0.5001214162223698,\n",
       " -0.2813377769259457,\n",
       " -0.390981341127121,\n",
       " -0.4125203038626616,\n",
       " -0.41688171168027227,\n",
       " -0.36885389750241726,\n",
       " -0.37847522041664955,\n",
       " -0.42096693260546336,\n",
       " -0.4091209646508728,\n",
       " -0.2725588248083069,\n",
       " -0.42812828841595657,\n",
       " -0.3441464320172023,\n",
       " -0.3733724036606663,\n",
       " -0.5485030375136666,\n",
       " -0.5158424617329777,\n",
       " -0.4718984389303215,\n",
       " -0.3965168609587659,\n",
       " -0.4426358022441339,\n",
       " -0.41781606804072696,\n",
       " -0.3952630532355593,\n",
       " -0.43596392736277123,\n",
       " -0.4873656557556513,\n",
       " -0.3545943326587561,\n",
       " -0.34255512327452653,\n",
       " -0.3449108276056927,\n",
       " -0.40963007320824324,\n",
       " -0.49510674235671615,\n",
       " -0.43749994403966963,\n",
       " -0.3309068313656237,\n",
       " -0.32500850045500335,\n",
       " -0.2958606508993221,\n",
       " -0.4483203172433382,\n",
       " -0.3154676046296432,\n",
       " -0.36291444924129457,\n",
       " -0.3829353503899906,\n",
       " -0.47004095708012167,\n",
       " -0.4432924117413412,\n",
       " -0.3074811103789779,\n",
       " -0.25243432724497306,\n",
       " -0.34027842512861844,\n",
       " -0.5724958022126925,\n",
       " -0.4306618602656742,\n",
       " -0.5413802580239169,\n",
       " -0.4180075929353795,\n",
       " -0.5305291414366504,\n",
       " -0.5766052574447696,\n",
       " -0.5867198701199453,\n",
       " -0.377461350206489,\n",
       " -0.43708095809847347,\n",
       " -0.41837190285038084,\n",
       " -0.4035006149070215,\n",
       " -0.5839642046361572,\n",
       " -0.3452180519710374,\n",
       " -0.4193906485830281,\n",
       " -0.2593133296431531,\n",
       " -0.5440439257690179,\n",
       " -0.3891140359784469,\n",
       " -0.4570363672265382,\n",
       " -0.35209125701211924,\n",
       " -0.48234619054180916,\n",
       " -0.46919539814100913,\n",
       " -0.4229347163686326,\n",
       " -0.4314017664230997,\n",
       " -0.4012195511931138,\n",
       " -0.46904874928560464,\n",
       " -0.4604330736716673,\n",
       " -0.5458030047094253,\n",
       " -0.3240995572893518,\n",
       " -0.2682269228035871,\n",
       " -0.47781349213411317,\n",
       " -0.594740786335202,\n",
       " -0.3893783901878663,\n",
       " -0.3205159619761007,\n",
       " -0.3197065851548714,\n",
       " -0.4947248260626031,\n",
       " -0.5560841919712484,\n",
       " -0.3368774621483375,\n",
       " -0.36418883596708546,\n",
       " -0.5242315626616131,\n",
       " -0.47916495113553303,\n",
       " -0.5342901131461891,\n",
       " -0.38634614563473685,\n",
       " -0.5537500337727803,\n",
       " -0.3658847494637172,\n",
       " -0.3427341489121042,\n",
       " -0.3259461605244742,\n",
       " -0.37471160476200416,\n",
       " -0.47646308523279757,\n",
       " -0.33152580535465254,\n",
       " -0.49655696129554,\n",
       " -0.3695848397182594,\n",
       " -0.23955663824756157,\n",
       " -0.357310632189316,\n",
       " -0.43144433653181735,\n",
       " -0.34584695793654746,\n",
       " -0.33343963457925935,\n",
       " -0.4883349882810401,\n",
       " -0.5989890977972172,\n",
       " -0.5114792070288926,\n",
       " -0.4087107900618061,\n",
       " -0.3237564725988675,\n",
       " -0.3672857141183006,\n",
       " -0.40322303873244497,\n",
       " -0.3125610213539933,\n",
       " -0.3972257811633135,\n",
       " -0.40352952290885963,\n",
       " -0.5302346490318282,\n",
       " -0.49280432426739523,\n",
       " -0.4544272328693395,\n",
       " -0.283087384568329,\n",
       " -0.44616786815190007,\n",
       " -0.4087464492542328,\n",
       " -0.40695765117970384,\n",
       " -0.5414425714922054,\n",
       " -0.5165352873719591,\n",
       " -0.4861789391305382,\n",
       " -0.39841345567231456,\n",
       " -0.3786907347479717,\n",
       " -0.6216870354281933,\n",
       " -0.37456394285160477,\n",
       " -0.4164811979422269,\n",
       " -0.4289931247188956,\n",
       " -0.4855403344274381,\n",
       " -0.4155609944428916,\n",
       " -0.41908295977104165,\n",
       " -0.38988169453804533,\n",
       " -0.5133366693223705,\n",
       " -0.3152140113473959,\n",
       " -0.482908607700692,\n",
       " -0.5431566762062522,\n",
       " -0.4225735122214883,\n",
       " -0.40956512658458644,\n",
       " -0.38158183801005585,\n",
       " -0.40577121998525456,\n",
       " -0.4314854426655557,\n",
       " -0.5080527563267178,\n",
       " -0.49260469665944884,\n",
       " -0.3633940801477857,\n",
       " -0.3221242272725085,\n",
       " -0.3770029072151126,\n",
       " -0.38168418394038706,\n",
       " -0.4405383999925163,\n",
       " -0.36733531744884335,\n",
       " -0.5121382475253625,\n",
       " -0.495404466216728,\n",
       " -0.4867991082961325,\n",
       " -0.3027361735094818,\n",
       " -0.4199755658155129,\n",
       " -0.42448991971279254,\n",
       " -0.5213962694239734,\n",
       " -0.33799378491242144,\n",
       " -0.5171229391702904,\n",
       " -0.45532192659022347,\n",
       " -0.44598440595061906,\n",
       " -0.49752246944825074,\n",
       " -0.3745588836757312,\n",
       " -0.5048553096103724,\n",
       " -0.38885874678566507,\n",
       " -0.48557073985933613,\n",
       " -0.29462807986018624,\n",
       " -0.39441669165461507,\n",
       " -0.5054046052072906,\n",
       " -0.43649066417271865,\n",
       " -0.4515161179497526,\n",
       " -0.3888477195438873,\n",
       " -0.4161766089025858,\n",
       " -0.49389875345949563,\n",
       " -0.48945450914555066,\n",
       " -0.5280100549696627,\n",
       " -0.5220995264032164,\n",
       " -0.38900504267134894,\n",
       " -0.4508012086798272,\n",
       " -0.48369706754014413,\n",
       " -0.1970522482522895,\n",
       " -0.46733715432730905,\n",
       " -0.4747749836550781,\n",
       " -0.3404462250693827,\n",
       " -0.23819398817916684,\n",
       " -0.447428168115002,\n",
       " -0.3852356892911009,\n",
       " -0.4129726138818409,\n",
       " -0.3956487420442197,\n",
       " -0.2971429071660844,\n",
       " -0.3336352548105904,\n",
       " -0.394348139977632,\n",
       " -0.40856844783685503,\n",
       " -0.3987174384603283,\n",
       " -0.4069085949692644,\n",
       " -0.39766560057431855,\n",
       " -0.48361200459888654,\n",
       " -0.37157707234509524,\n",
       " -0.47090496884617106,\n",
       " -0.49122867844928214,\n",
       " -0.33029372253878875,\n",
       " -0.6290378986408036,\n",
       " -0.5234690702659149,\n",
       " -0.5857208170401043,\n",
       " -0.47688743794866106,\n",
       " -0.36480156063630914,\n",
       " -0.4290849245420847,\n",
       " -0.49148959841068546,\n",
       " -0.513522583004687,\n",
       " -0.5733252294337285,\n",
       " -0.2912877842007003,\n",
       " -0.44620536543423034,\n",
       " -0.5087929781501328,\n",
       " -0.45250853750421877,\n",
       " -0.38025660665174504,\n",
       " -0.49775975406375367,\n",
       " -0.44230213537081076,\n",
       " -0.4216911402762636,\n",
       " -0.37925546597338333,\n",
       " -0.4705013709754795,\n",
       " -0.43661147430213365,\n",
       " -0.1914916169509679,\n",
       " -0.44264035711658806,\n",
       " -0.39745775560399255,\n",
       " -0.5016364892134096,\n",
       " -0.37292943441327664,\n",
       " -0.37525644064573327,\n",
       " -0.5249285926481286,\n",
       " -0.5324748429201263,\n",
       " -0.45272700562311624,\n",
       " -0.38649150288424816,\n",
       " -0.42710851893823204,\n",
       " -0.36284529157599793,\n",
       " -0.4884281150816513,\n",
       " -0.3714525732050758,\n",
       " -0.39583446969317243,\n",
       " -0.5973183446712991,\n",
       " -0.4964655665605636,\n",
       " -0.4779232561030132,\n",
       " -0.45732319312306113,\n",
       " -0.3818008016800305,\n",
       " -0.36957086596089916,\n",
       " -0.3079860624161883,\n",
       " -0.43114563000545925,\n",
       " -0.36505229829518854,\n",
       " -0.4965639049957669,\n",
       " -0.42263334384016843,\n",
       " -0.5746803675619171,\n",
       " -0.4986991730994551,\n",
       " -0.43121119576623423,\n",
       " -0.3237264420551132,\n",
       " -0.49675975493991376,\n",
       " -0.5565977580986503,\n",
       " -0.5937446667317212,\n",
       " -0.36485519870593197,\n",
       " -0.3882630431499612,\n",
       " -0.4533412719963597,\n",
       " -0.5162463057332842,\n",
       " -0.5001824631768252,\n",
       " -0.40506756480704587,\n",
       " -0.4014835505184196,\n",
       " -0.28809799542982095,\n",
       " -0.5487066040400308,\n",
       " -0.5239544562618745,\n",
       " -0.3261981730297772,\n",
       " -0.44054778713179765,\n",
       " -0.2631563386768476,\n",
       " -0.4548566240461429,\n",
       " -0.49288391916165425,\n",
       " -0.3317170925713868,\n",
       " -0.3720903038587828,\n",
       " -0.5468573686114018,\n",
       " -0.35959782113078625,\n",
       " -0.43076368012119637,\n",
       " -0.46206180978821115,\n",
       " -0.5573024819298376,\n",
       " -0.47708687951419737,\n",
       " -0.46546838037878163,\n",
       " -0.46493918711215587,\n",
       " -0.48500391790311936,\n",
       " -0.4817299493104509,\n",
       " -0.47445490532725165,\n",
       " -0.46964190123054256,\n",
       " -0.408149452548756,\n",
       " -0.43319012001913715,\n",
       " -0.3871154244497186,\n",
       " -0.2921605999037315,\n",
       " -0.24696506828156092,\n",
       " -0.4539109478303886,\n",
       " -0.27927081017739547,\n",
       " -0.48908012338599954,\n",
       " -0.3717535757879404,\n",
       " -0.36161507067193854,\n",
       " -0.3534486488127347,\n",
       " -0.3957173383786757,\n",
       " -0.4585731728962761,\n",
       " -0.3416843523975151,\n",
       " -0.5422250870042347,\n",
       " -0.28062762266510966,\n",
       " -0.47246657094638284,\n",
       " -0.39374951099652283,\n",
       " -0.3516615196979223,\n",
       " -0.36159331582711357,\n",
       " -0.5956264987794712,\n",
       " -0.406768096934566,\n",
       " -0.35153881982486934,\n",
       " -0.5376516917208082,\n",
       " -0.5558823521793786,\n",
       " -0.6051041081505618,\n",
       " -0.40192698685711725,\n",
       " -0.4934649567145762,\n",
       " -0.4534823430871898,\n",
       " -0.4398040482636605,\n",
       " -0.443497127667392,\n",
       " -0.5426484120757601,\n",
       " -0.4382452827929071,\n",
       " -0.6148603225884441,\n",
       " -0.3358380648920769,\n",
       " -0.4427248640448242,\n",
       " -0.3876108348350016,\n",
       " -0.2684109670208404,\n",
       " -0.5546421325028168,\n",
       " -0.45933722783898384,\n",
       " -0.3296468599639988,\n",
       " -0.4878677828972731,\n",
       " -0.321809010912703,\n",
       " -0.3331661594937891,\n",
       " -0.4857617726726816,\n",
       " -0.5318477389800625,\n",
       " -0.4246557463479183,\n",
       " -0.4340824065209893,\n",
       " -0.38637670663608337,\n",
       " -0.48973543046977747,\n",
       " -0.44032990076406153,\n",
       " -0.2539847926584907,\n",
       " -0.4461582502771851,\n",
       " -0.414198090317061,\n",
       " -0.4365014494251876,\n",
       " -0.4303296985498393,\n",
       " -0.4395790557394178,\n",
       " -0.39715810894833253,\n",
       " -0.421699205967557,\n",
       " -0.36619650337529047,\n",
       " -0.47524717354355517,\n",
       " -0.5128659932867763,\n",
       " -0.37960001766213064,\n",
       " -0.501334012174546,\n",
       " -0.41538516370742945,\n",
       " -0.2756956313715972,\n",
       " -0.5587136359289869,\n",
       " -0.5667341759090238,\n",
       " -0.26119380987282176,\n",
       " -0.504525312706123,\n",
       " -0.3919063814013066,\n",
       " -0.4614268915913987,\n",
       " -0.4372674626699947,\n",
       " -0.32383465448953175,\n",
       " -0.22828681542785656,\n",
       " -0.3258579495715355,\n",
       " -0.4189423736297444,\n",
       " -0.3906783002739832,\n",
       " -0.48417791931369103,\n",
       " -0.26794594129541843,\n",
       " -0.3357021747516132,\n",
       " -0.413403801376148,\n",
       " -0.3978678834107258,\n",
       " -0.30084805542237714,\n",
       " -0.40672081209803446,\n",
       " -0.4256824243135486,\n",
       " -0.40979806876144476,\n",
       " -0.5032618863488592,\n",
       " -0.44628398644715245,\n",
       " -0.5604946010940612,\n",
       " -0.3860995623912079,\n",
       " -0.4197174710146629,\n",
       " -0.37343662187522186,\n",
       " -0.3993393198049548,\n",
       " -0.5379844919541651,\n",
       " -0.5874288465501437,\n",
       " -0.40686479592448244,\n",
       " -0.45169145877334915,\n",
       " -0.5618138157586874,\n",
       " -0.44777839137168157,\n",
       " -0.3438909893298833,\n",
       " -0.4642956783538052,\n",
       " -0.40236535197682627,\n",
       " -0.48187788210817456,\n",
       " -0.5515717158371427,\n",
       " -0.6657468102600143,\n",
       " -0.4379577584864311,\n",
       " -0.47999959735804154,\n",
       " -0.45329488333373646,\n",
       " -0.411345696775196,\n",
       " -0.408270747925404,\n",
       " -0.3494745596510484,\n",
       " -0.2512084617835997,\n",
       " -0.6822939173312235,\n",
       " -0.39798711721776453,\n",
       " -0.39563567423873325,\n",
       " -0.5221433266743586,\n",
       " -0.5577327751501916,\n",
       " -0.3852179661640262,\n",
       " -0.45279106591105006,\n",
       " -0.3660525798945841,\n",
       " -0.2887321994635044,\n",
       " -0.5503551720439708,\n",
       " -0.295813331073337,\n",
       " -0.43342773173706295,\n",
       " -0.5044947088501015,\n",
       " -0.38130290887781265,\n",
       " -0.394909002494545,\n",
       " -0.3811863624729716,\n",
       " -0.4008631214349441,\n",
       " -0.46102392054380587,\n",
       " -0.4090281104786259,\n",
       " -0.463451099522619,\n",
       " -0.24073229806123272,\n",
       " -0.2765336245179465,\n",
       " -0.45987277020271716,\n",
       " -0.35860119629706966,\n",
       " -0.3567310668585642,\n",
       " -0.394398333122192,\n",
       " -0.5368185999076155,\n",
       " -0.4147889340742026,\n",
       " -0.49925965009988693,\n",
       " -0.38636246557200415,\n",
       " -0.2859944299604943,\n",
       " -0.33586454121790127,\n",
       " -0.44941986279167667,\n",
       " -0.5476707675433254,\n",
       " -0.5668146041766415,\n",
       " -0.45087331922325047,\n",
       " -0.5211479080578533,\n",
       " -0.6644329811253434,\n",
       " -0.6728986190361133,\n",
       " -0.43113082057006213,\n",
       " -0.40066380215947395,\n",
       " -0.4459070316377555,\n",
       " -0.5101542727072667,\n",
       " -0.4211184150260863,\n",
       " -0.26908991111060443,\n",
       " -0.4613783580428784,\n",
       " -0.35138173665262984,\n",
       " -0.1910872869874783,\n",
       " -0.3985892867384929,\n",
       " -0.4953547774058042,\n",
       " -0.5528757123283565,\n",
       " -0.48225479087343176,\n",
       " -0.51219027313171,\n",
       " -0.49156762799492754,\n",
       " -0.707690289362059,\n",
       " -0.3646571095942647,\n",
       " -0.36237082739046644,\n",
       " -0.3162946368719609,\n",
       " -0.4067758241360709,\n",
       " -0.39050468822414053,\n",
       " -0.48095809405598877,\n",
       " -0.3242406299875851,\n",
       " -0.3493919418213256,\n",
       " -0.4602998123947556,\n",
       " -0.40066005765641277,\n",
       " -0.4811992347855149,\n",
       " -0.37504415819635534,\n",
       " -0.47457802900185864,\n",
       " -0.3770837320376349,\n",
       " -0.40864647823256495,\n",
       " -0.47195575971358195,\n",
       " -0.40306591595832303,\n",
       " -0.5962483045204375,\n",
       " -0.4550819974967095,\n",
       " -0.3767973512255038,\n",
       " -0.451013663924863,\n",
       " -0.33668751398799535,\n",
       " -0.5245256055449671,\n",
       " -0.5905081707022592,\n",
       " -0.35364934547506127,\n",
       " -0.48596537212518376,\n",
       " -0.6433285037178964,\n",
       " -0.3916624581908495,\n",
       " -0.39483937712386064,\n",
       " -0.41576416943021105,\n",
       " -0.37733604787532726,\n",
       " -0.4016754135154944,\n",
       " -0.4470213801076594,\n",
       " -0.3857564245777089,\n",
       " -0.48185786172120176,\n",
       " -0.48140345095039083,\n",
       " -0.43058940056325085,\n",
       " -0.4947008891031604,\n",
       " -0.5455488814212359,\n",
       " -0.4258913573773645,\n",
       " -0.48349228249740595,\n",
       " -0.38006810554262993,\n",
       " -0.3924768783790109,\n",
       " -0.486112297172182,\n",
       " -0.38149484423564456,\n",
       " -0.47901680843482153,\n",
       " -0.5081355293985864,\n",
       " -0.5742182467284322,\n",
       " -0.47845741909184464,\n",
       " -0.5072179019279693,\n",
       " -0.377969874543555,\n",
       " -0.4009291253936208,\n",
       " -0.4990846020128447,\n",
       " -0.3276705255228104,\n",
       " -0.5108139477149904,\n",
       " -0.3796809860380624,\n",
       " -0.6113737272378749,\n",
       " -0.4615749224508233,\n",
       " -0.45046464410182613,\n",
       " -0.5254325383117586,\n",
       " -0.4781818672925548,\n",
       " -0.3370438123070649,\n",
       " -0.5186770741166468,\n",
       " -0.42016920356613346,\n",
       " -0.2999310265502675,\n",
       " -0.46792861788448925,\n",
       " -0.4664956635817866,\n",
       " -0.4839520408184523,\n",
       " -0.49380291300468077,\n",
       " -0.3898576509116026,\n",
       " -0.3427591397407865,\n",
       " -0.4655888309310058,\n",
       " -0.4903528568206243,\n",
       " -0.35978748075878425,\n",
       " -0.38404792435391083,\n",
       " -0.5400991872385756,\n",
       " -0.4423958602976086,\n",
       " -0.43442097124977613,\n",
       " -0.5154160918451348,\n",
       " -0.3994579517352894,\n",
       " -0.5867928399996066,\n",
       " -0.36414794254001076,\n",
       " -0.3100208795517574,\n",
       " -0.43922370816520495,\n",
       " -0.40019328966049045,\n",
       " -0.461340089269771,\n",
       " -0.4252705796757741,\n",
       " -0.47495135722048926,\n",
       " -0.3827265305170023,\n",
       " -0.3670371495763359,\n",
       " -0.4789051692246271,\n",
       " -0.5631468954319498,\n",
       " -0.3270532526639528,\n",
       " -0.456208883259536,\n",
       " -0.5677644494108259,\n",
       " -0.6203408134203872,\n",
       " -0.561552038409868,\n",
       " -0.5341424689757014,\n",
       " -0.3733028752152652,\n",
       " -0.4680180400257961,\n",
       " -0.5565381736069238,\n",
       " -0.2840634831467811,\n",
       " -0.45738841737326225,\n",
       " -0.47049238429791906,\n",
       " -0.4683144965968326,\n",
       " -0.48845131022799626,\n",
       " -0.4737557696448015,\n",
       " -0.3439719385105772,\n",
       " -0.4724098740874213,\n",
       " -0.3930183394044915,\n",
       " -0.3511405096330113,\n",
       " -0.4453170407363081,\n",
       " -0.4915684709836486,\n",
       " -0.5894289603568635,\n",
       " -0.38038412190404486,\n",
       " -0.4075291925668605,\n",
       " -0.4576138095352611,\n",
       " -0.3932715405301559,\n",
       " -0.4451820239603098,\n",
       " -0.3818678063602383,\n",
       " -0.3339711001401484,\n",
       " -0.4285671230951508,\n",
       " -0.546878797535209,\n",
       " -0.33535392260184066,\n",
       " -0.5294608086197691,\n",
       " -0.4773536175494424,\n",
       " -0.48259773716268406,\n",
       " -0.5001590833494,\n",
       " -0.5397776364156097,\n",
       " -0.46503634139923616,\n",
       " -0.42652079928376774,\n",
       " -0.3373594228216897,\n",
       " -0.2880933721739854,\n",
       " -0.28819011903741315,\n",
       " -0.3458709517706609,\n",
       " -0.447952084083861,\n",
       " -0.5191593979570026,\n",
       " -0.42006762406260234,\n",
       " -0.42227608615833717,\n",
       " -0.5179290831822149,\n",
       " -0.45727971573099363,\n",
       " -0.34539210086031186,\n",
       " -0.4293647538850321,\n",
       " -0.5212929616972501,\n",
       " -0.5521428690500663,\n",
       " -0.4810180336661508,\n",
       " -0.39349968234648897,\n",
       " -0.5050709194146366,\n",
       " -0.34506495693966927,\n",
       " -0.354533865637542,\n",
       " -0.4512178095063736,\n",
       " -0.5584460874580446,\n",
       " -0.4087899408463381,\n",
       " -0.409792216250561,\n",
       " -0.4829174615060946,\n",
       " -0.4002574352339929,\n",
       " -0.4357778051107036,\n",
       " -0.5382718170360866,\n",
       " -0.5046815914180355,\n",
       " -0.5954729328443203,\n",
       " -0.4342735730938572,\n",
       " -0.3877196683893794,\n",
       " -0.39480808629205333,\n",
       " -0.5358480378400966,\n",
       " -0.4273718760887067,\n",
       " -0.4088579902063546,\n",
       " -0.4489086922945865,\n",
       " -0.35286120226119794,\n",
       " -0.42252834429610975,\n",
       " -0.3938446361540598,\n",
       " -0.48395468360802507,\n",
       " -0.5519353332766515,\n",
       " -0.4244995510632618,\n",
       " -0.504317042309587,\n",
       " -0.3648841042471249,\n",
       " -0.5186853634073098,\n",
       " -0.37346405512142694,\n",
       " -0.5374245088349152,\n",
       " -0.5999289628130822,\n",
       " -0.5471659559239822,\n",
       " -0.453145936446619,\n",
       " -0.2960681004656499,\n",
       " -0.24754430445578252,\n",
       " -0.4449338570280651,\n",
       " -0.6460420137084274,\n",
       " -0.31756668921784503,\n",
       " -0.22702546397489987,\n",
       " -0.43160126683884437,\n",
       " -0.3952099304359917,\n",
       " -0.53517663434796,\n",
       " -0.4595089322414557,\n",
       " -0.3665857807165187,\n",
       " -0.42961033989027,\n",
       " -0.5940765544610339,\n",
       " -0.4869961241881093,\n",
       " -0.3854938564580773,\n",
       " -0.43671501721702366,\n",
       " -0.42790895057488165,\n",
       " -0.46776943729163356,\n",
       " -0.47167525155888945,\n",
       " -0.4109876644678128,\n",
       " -0.3731568833642196,\n",
       " -0.3819397177172445,\n",
       " -0.3594458806020162,\n",
       " -0.541717370657062,\n",
       " -0.5037377433955131,\n",
       " -0.5305870186895802,\n",
       " -0.7750474189713569,\n",
       " -0.36801184493946437,\n",
       " -0.39781913155189935,\n",
       " -0.4628156888871002,\n",
       " -0.5957511356977925,\n",
       " -0.3086672892702042,\n",
       " -0.4723569867394288,\n",
       " -0.5353151739994203,\n",
       " -0.5707141684130681,\n",
       " -0.39626830450608524,\n",
       " -0.38989379625917137,\n",
       " -0.339588833787427,\n",
       " -0.5667557492703323,\n",
       " -0.4873830293708875,\n",
       " -0.33382071785648826,\n",
       " -0.42466452109755365,\n",
       " -0.5426822778514849,\n",
       " -0.5225722600415735,\n",
       " -0.5165997915045536,\n",
       " -0.47916140104859917,\n",
       " -0.4002149523696931,\n",
       " -0.5350167982598074,\n",
       " -0.5046775368923171,\n",
       " -0.4516180406049341,\n",
       " -0.4755875303442367,\n",
       " -0.36326162769556003,\n",
       " -0.5319327953727471,\n",
       " -0.4373928829751311,\n",
       " -0.5142601826886781,\n",
       " -0.35207678680223836,\n",
       " -0.5505663682812515,\n",
       " -0.480122387456347,\n",
       " -0.3944832638913825,\n",
       " -0.44095226925569253,\n",
       " -0.4547841073017561,\n",
       " -0.5773873519026845,\n",
       " -0.6053943946678909,\n",
       " -0.41720188144951015,\n",
       " -0.4892581719285511,\n",
       " -0.41474120512373985,\n",
       " -0.4863037270357032,\n",
       " -0.6464266837361359,\n",
       " -0.5080056848761333,\n",
       " -0.4464156199010524,\n",
       " -0.5861981929040845,\n",
       " -0.44197885897652667,\n",
       " -0.4132392990568847,\n",
       " -0.4968594603180171,\n",
       " -0.5597396408749229,\n",
       " -0.3979896090196378,\n",
       " -0.5731929610153931,\n",
       " -0.5253746062136698,\n",
       " -0.4756345824485124,\n",
       " -0.5275330690238904,\n",
       " -0.4804193225071759,\n",
       " -0.39091167394503745,\n",
       " -0.42061666767903766,\n",
       " -0.3627335045017835,\n",
       " -0.45894192467038253,\n",
       " -0.5415808726947619,\n",
       " -0.3822121907680246,\n",
       " -0.3429464315000819,\n",
       " -0.5271665229641903,\n",
       " -0.44644123500394844,\n",
       " -0.2956079971879549,\n",
       " -0.5411453572114624,\n",
       " -0.3442560229100705,\n",
       " -0.5049469555372752,\n",
       " -0.63296275192109,\n",
       " -0.38844133289171046,\n",
       " -0.2879668045376494,\n",
       " -0.40320879120206793,\n",
       " -0.5467313241112977,\n",
       " -0.4816538634187812,\n",
       " -0.5500658519370232,\n",
       " -0.25759748403122285,\n",
       " -0.4402974020297053,\n",
       " -0.36616215708361405,\n",
       " -0.4839041183944842,\n",
       " -0.5054285178070206,\n",
       " -0.5666335302955101,\n",
       " -0.2797382199733326,\n",
       " -0.5090553505943975,\n",
       " -0.4077599858768474,\n",
       " -0.44030945945419214,\n",
       " -0.46389764602600736,\n",
       " -0.5693289807579027,\n",
       " -0.4587090315645235,\n",
       " -0.4094674922614808,\n",
       " -0.40373524481025325,\n",
       " -0.2830019492329764,\n",
       " -0.3902709926420794,\n",
       " -0.49019792772669946,\n",
       " -0.5317220569216563,\n",
       " -0.5147449909244953,\n",
       " -0.4129195577379341,\n",
       " -0.46230776619898606,\n",
       " -0.46782256701969105,\n",
       " -0.4260708730561605,\n",
       " -0.493887009344636,\n",
       " -0.5191425447865647,\n",
       " -0.3970417826060147,\n",
       " -0.3070549030349644,\n",
       " -0.5558372478742435,\n",
       " -0.25717505525928663,\n",
       " -0.31272833710533804,\n",
       " -0.4648295229031951,\n",
       " -0.4936520727088332,\n",
       " -0.49766798375359333,\n",
       " -0.4389297392270891,\n",
       " -0.4766026414303424,\n",
       " -0.42199921252359246,\n",
       " -0.4942986867941875,\n",
       " -0.42745727298087693,\n",
       " -0.4009305915381762,\n",
       " -0.6111482184314143,\n",
       " -0.6019762841739057,\n",
       " -0.4465089341657071,\n",
       " -0.41155368648953283,\n",
       " -0.5018162681688119,\n",
       " -0.5243372601066832,\n",
       " -0.4995400374212136,\n",
       " -0.28991603098880103,\n",
       " -0.41834049764726855,\n",
       " -0.42694206462022044,\n",
       " -0.49740804601026195,\n",
       " -0.655005327559355,\n",
       " -0.4260460173926285,\n",
       " -0.32001879132368066,\n",
       " -0.5475178651852688,\n",
       " -0.37958950218755166,\n",
       " -0.40268991015439914,\n",
       " -0.5258143891191519,\n",
       " -0.5227369823429169,\n",
       " -0.5986609871273892,\n",
       " -0.36021661682214995,\n",
       " -0.46153472588363237,\n",
       " -0.6403244369264729,\n",
       " -0.46798191917223353,\n",
       " -0.4061713054745449,\n",
       " -0.3975528560148133,\n",
       " -0.6379702955915095,\n",
       " -0.48844282113895626,\n",
       " -0.5096784515304411,\n",
       " -0.46276497130766875,\n",
       " -0.4473250849119061,\n",
       " -0.3601243967096475,\n",
       " -0.5159150996211697,\n",
       " -0.49619068626161705,\n",
       " -0.4967785241300897,\n",
       " -0.3984673929572726,\n",
       " -0.3832909376651213,\n",
       " -0.37503746656934206,\n",
       " -0.563349015076513,\n",
       " -0.5777943006451158,\n",
       " -0.4560830154492669,\n",
       " -0.2841623741054869,\n",
       " -0.49215036284772434,\n",
       " -0.35167984476830527,\n",
       " -0.4221078129826294,\n",
       " -0.404780439058277,\n",
       " -0.412764044118468,\n",
       " -0.39013463027809814,\n",
       " -0.35461793611470976,\n",
       " -0.3368959048670537,\n",
       " -0.29946351323920706,\n",
       " -0.37425320420429975,\n",
       " -0.4707200913784206,\n",
       " -0.4439405545039376,\n",
       " -0.5768853574660808,\n",
       " -0.49662351980895175,\n",
       " -0.45703399448969156,\n",
       " -0.20869445329593111,\n",
       " -0.3241571330049277,\n",
       " -0.4830794196150679,\n",
       " -0.49495637911382623,\n",
       " -0.46683757024370653,\n",
       " -0.30609763330114403,\n",
       " -0.4153189466331686,\n",
       " -0.6009397466042797,\n",
       " -0.587200247165616,\n",
       " -0.4769595881125624,\n",
       " -0.36767768966028,\n",
       " -0.49837671430373953,\n",
       " -0.6542971333236992,\n",
       " -0.512180549425899,\n",
       " -0.5359566454426922,\n",
       " -0.4887949188182047,\n",
       " -0.49611660833135207,\n",
       " -0.4222561691762864,\n",
       " -0.5094991959426298,\n",
       " -0.4693476268143543,\n",
       " -0.48602354960924105,\n",
       " -0.5291301408507617,\n",
       " -0.49254965421760455,\n",
       " -0.3819722158273182,\n",
       " -0.30165463300473544,\n",
       " -0.3488457575180829,\n",
       " -0.5349534924544989,\n",
       " -0.6177173644085268,\n",
       " -0.4230415283545854,\n",
       " -0.41398308922054555,\n",
       " -0.5901561785402835,\n",
       " -0.2596095804591856,\n",
       " -0.42103149130349854,\n",
       " -0.4444867500106218,\n",
       " -0.377530775853798,\n",
       " -0.5526530403401255,\n",
       " -0.5410842111258216,\n",
       " -0.4729688687060353,\n",
       " -0.4157427621442363,\n",
       " -0.4527480398504978,\n",
       " -0.416578158987739,\n",
       " -0.6503004845353275,\n",
       " -0.7639071546826437,\n",
       " -0.3538546954156575,\n",
       " -0.4345413125393319,\n",
       " -0.5846018480995917,\n",
       " -0.40979956515472904,\n",
       " -0.43058626103236464,\n",
       " -0.43891597764886403,\n",
       " -0.3580680206961009,\n",
       " -0.4488101318086932,\n",
       " -0.5114155849742271,\n",
       " -0.510064956302376,\n",
       " -0.5226485333612445,\n",
       " -0.6420444899033662,\n",
       " -0.3049507266503413,\n",
       " -0.12930622230621897,\n",
       " -0.3140727898826596,\n",
       " ...]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
